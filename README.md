# V-Look Project

### Introduction

V-Look 프로젝트란, 가상 피팅 서비스( virtual fitting service )에 대한 프로젝트로써, 자신이 직접 옷을 입어보지 않아도 여러 옷이 화면에 입은 것처럼 보여주는 서비스를 말한다. 우리 팀
'맵시' 조는 CNN( Convolutional neural networks )의 방법을 통해 구현을 하고, 마지막에 GAN (Generative Adversarial Network)방법을 이용하여 최종 구현을 한다.
![f1](https://user-images.githubusercontent.com/69288067/92193701-e9ee2600-eea3-11ea-942d-7c791a7e62df.gif)

위 사진과 같은 형태로 사람을 인지하여 옷을 입혀주며, 컴퓨터에 각종 옷을 데이터화 시켜서 러닝을 시켜줌으로써 최종 구현을 목표로 잡고있다. 더 나아가 이러한 서비스가 상용화가 된다면 각 집에 있는 set-top box( 셋톱박스 )에 이 서비스를 활용하여 집에서도 카메라를 통해 자신이 사고싶은 옷을 매칭시켜 바로 주문 할 수 있는 서비스를 구현하고자 한다.

## Code
 주요 코드및 설명문


## Data set
사람들이 입은 옷의 Edge, contour를 따기 위해 많은 사진들을 필요로 하였으며, 사진들은 Kaggle 사이트를 이용하여 데이터를 모았다.
ㅡ> 실제 사용하게 되면 data set을 모아서 올리기.


## Result

결과물- 최종 시연 될 영상 및 사진 첨부
